Для задач от бизнеса (11-24) Q&A пройдет 4 июня в 18:00

вопросы:
1) можно ли использовать внешние датасеты, или обучаться нужно только на предоставленном датасете?
2) можно ли трекать объект в случае видео для повышения качества распознавания, или _исключительно_ детектор объектов и передавать информацию между кадрами запрещено?
3) допустимо ли использование gradio в качестве интерфейса?
4) на каком железе (cpu/gpu) будет оцениваться скорость работы модели, и примерно на какую скорость работы (и при каком батче) нужно ориентироваться?
5) можно ли обучить несколько моделей разного размера чтобы организаторы сами выбрали оптимальное соотношение скорость/качество?
6) модели будут проверять на нормальных видео, а не на той... каше, которая в датасете?

нужен веб-сервис в контейнере с гайдом по развертыванию
нужен докер файл с инструкцией
проверка будет на Dell EMC PowerEdge C4140, gpu Tesla V100 16Гб, cpu Intel Xeon Gold 6152
клауд.ру (скорее всего) не дадут gpu goes brrrrrr xD
тестовые данные берутся из тех же источников?....
тестовые данные аналогичны выложенному датасету (....)
обещают расширенный датасет с большим количеством мелких объектов
из чата: разметка изображений часто сломана, нужно проверять
качество > скорость по субъективной оценке
тестовый датасет будет перепроверен по поводу разметки
загружаться будет видео до 1 гигабайта, в сумме до 100 гигабайт
будут камеры 4к / 90 градусов обзор / х30 зум / потом добавят тепловизоры
при проверке - будут доступны и общедоступные и приватные данные
RTMP видео будет небольшим плюсом
можно использовать любые датасеты
трекинг судя по всему не нужен/нежелателен
десятки миллисекунд, на GPU
gradio использовать можно
несколько моделей разного размера для организаторов обучать можно
скорость будет оцениваться на видео (нужен батч)
у контейнера будет доступ в интернет
видео при тестировании будут загружаться по очереди
пропорции открытых/закрытых данных в трейне/тесте примерно одинаковые планируются
размер докер образа не ограничен
расширение датасета будет до четверга
confidence 0.25 задается самим
классы в тесте будут сбалансированы
минимальный размер объекта около 10х10
видео будет до 4к
размер картинок на тесте разный
в основном тестовые данные без снега и дождя, нормальная погода, время года весна-лето
формат картинок разный, .jpg/.png/разные
ночные фото не планируются пока
идея решения - нестандартные идеи
полнота решения - выполнение тз
качество кода - стандарты оформления кода
развернутость решения - контейнер запускается без проблем
полнота описания - документация на код/решение
если контейнер грохнется - возьмут модель и прогонят через видео/картинки сами, xywh метки


-----------

модель - yolo v8-9-10(?)
данные - напихали всякого хлама в кучу
  по описанию задачи - нужно фокусироваться на мелких объектах, возможно можно просто выкинуть все bbox, которые занимают много места на экране
  https://gitlab.aicrowd.com/amazon-prime-air/airborne-detection-starter-kit/-/blob/master/docs/DATASET.md - возможно этот датасет еще живой, было бы отлично
  https://s3.amazonaws.com/airborne-obj-detection-challenge-training/part1/Images/0001ba865c8e410e88609541b8f55ffc/15549773494832603520001ba865c8e410e88609541b8f55ffc.png - явно живой
  качество > размера, и _особенно_ это относится к той куче хлама, которую дали в виде датасета
тренировка - на данный момент нужно надергать несколько сотен _нормальных_ картинок из датасета и проверять в целом работает/нет, не гонясь за метриками

нужно побродить по кагглу и поискать object detection соревнования, почитать свежие общие подходы
  итог - свежих object detection соревнований нету, не очень свежие все в основном yolo
нужно побродить по гуглу и поискать датасеты с дронами/птицами/самолетами

сервер - возможно можно наследоваться от https://cloud.ru/ru/docs/aicloud/mlspace/concepts/environments__basic-images-list__jobs.html , чтобы не париться с баном докера
  нужно найти какой-то максимально простой веб-сервер для развертывания модели
  нужно понять как вообще эту модель дергать по апи

презентация - zzzz
документация - zzzz